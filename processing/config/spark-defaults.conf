# Spark Configuration for Chainalytics Project

# Iceberg configurations
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local.type=hadoop
spark.sql.catalog.local.warehouse=s3a://warehouse/

# S3 (MinIO) configurations
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=password123
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# Hive Metastore configurations (if using Hive Metastore)
# spark.sql.warehouse.dir=s3a://warehouse/
# spark.hadoop.hive.metastore.uris=thrift://hive-metastore:9083

# Performance configurations
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.skewJoin.enabled=true
spark.serializer=org.apache.spark.serializer.KryoSerializer

# Event logging for History Server
spark.eventLog.enabled=true
spark.eventLog.dir=file:///tmp/spark-events
spark.history.fs.logDirectory=file:///tmp/spark-events

# Memory configurations
spark.driver.memory=1g
spark.executor.memory=2g

# Shuffle configurations
spark.shuffle.compress=true
spark.shuffle.spill.compress=true

# Dynamic allocation
spark.dynamicAllocation.enabled=false
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.maxExecutors=4

# Kafka configurations for streaming
spark.streaming.kafka.consumer.poll.ms=1000
spark.streaming.backpressure.enabled=true

# UI configurations
spark.ui.reverseProxy=true
spark.ui.reverseProxyUrl=/